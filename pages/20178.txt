https://en.wikipedia.org/wiki/Hardware_acceleration




Hardware acceleration - Wikipedia



































Jump to content







Main menu





Main menu
move to sidebar
hide



		Navigation
	


Main pageContentsCurrent eventsRandom articleAbout WikipediaContact us





		Contribute
	


HelpLearn to editCommunity portalRecent changesUpload fileSpecial pages



















Search











Search






















Appearance
















Donate

Create account

Log in








Personal tools





Donate Create account Log in





		Pages for logged out editors learn more



ContributionsTalk




























Contents
move to sidebar
hide




(Top)





1
Overview




Toggle Overview subsection





1.1
Computational equivalence of hardware and software








1.2
Stored-program computers








1.3
Hardware execution units








1.4
Emerging hardware architectures








1.5
Implementation metrics










2
Applications








3
Hardware acceleration units by application








4
See also








5
References








6
External links


















Toggle the table of contents







Hardware acceleration



23 languages




العربيةAzərbaycancaCatalàČeštinaDeutschEestiEspañolEuskaraفارسیFrançaisGalego한국어Bahasa IndonesiaItalianoNederlands日本語РусскийසිංහලСрпски / srpskiSuomiSvenskaУкраїнська中文

Edit links











ArticleTalk





English

















ReadEditView history







Tools





Tools
move to sidebar
hide



		Actions
	


ReadEditView history





		General
	


What links hereRelated changesUpload filePermanent linkPage informationCite this pageGet shortened URLDownload QR code





		Print/export
	


Download as PDFPrintable version





		In other projects
	


Wikimedia CommonsWikidata item





















Appearance
move to sidebar
hide










From Wikipedia, the free encyclopedia


For hardware accelerators in startup companies, see Seed accelerator.
Specialized computer hardware
This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: "Hardware acceleration" – news · newspapers · books · scholar · JSTOR (September 2014) (Learn how and when to remove this message)
A cryptographic accelerator card allows cryptographic operations to be performed at a faster rate.
Hardware acceleration is the use of computer hardware designed to perform specific functions more efficiently when compared to software running on a general-purpose central processing unit (CPU). Any transformation of data that can be calculated in software running on a generic CPU can also be calculated in custom-made hardware, or in some mix of both.
To perform computing tasks more efficiently, generally one can invest time and money in improving the software, improving the hardware, or both. There are various approaches with advantages and disadvantages in terms of decreased latency, increased throughput, and reduced energy consumption. Typical advantages of focusing on software may include greater versatility, more rapid development, lower non-recurring engineering costs, heightened portability, and ease of updating features or patching bugs, at the cost of overhead to compute general operations. Advantages of focusing on hardware may include speedup, reduced power consumption,[1] lower latency, increased parallelism[2] and bandwidth, and better utilization of area and functional components available on an integrated circuit; at the cost of lower ability to update designs once etched onto silicon and higher costs of functional verification, times to market, and the need for more parts. In the hierarchy of digital computing systems ranging from general-purpose processors to fully customized hardware, there is a tradeoff between flexibility and efficiency, with efficiency increasing by orders of magnitude when any given application is implemented higher up that hierarchy.[3] This hierarchy includes general-purpose processors such as CPUs,[4] more specialized processors such as programmable shaders in a GPU,[5] fixed-function implemented on field-programmable gate arrays (FPGAs),[6] and fixed-function implemented on application-specific integrated circuits (ASICs).[7]
Hardware acceleration is advantageous for performance, and practical when the functions are fixed, so updates are not as needed as in software solutions. With the advent of reprogrammable logic devices such as FPGAs, the restriction of hardware acceleration to fully fixed algorithms has eased since 2010, allowing hardware acceleration to be applied to problem domains requiring modification to algorithms and processing control flow.[8][9] The disadvantage, however, is that in many open source projects, it requires proprietary libraries that not all vendors are keen to distribute or expose, making it difficult to integrate in such projects.


Overview[edit]
Integrated circuits are designed to handle various operations on both analog and digital signals. In computing, digital signals are the most common and are typically represented as binary numbers. Computer hardware and software use this binary representation to perform computations. This is done by processing Boolean functions on the binary input, and then outputting the results for storage or further processing by other devices.

Computational equivalence of hardware and software[edit]
Because all Turing machines can run any computable function, it is always possible to design custom hardware that performs the same function as a given piece of software. Conversely, software can always be used to emulate the function of a given piece of hardware. Custom hardware may offer higher performance per watt for the same functions that can be specified in software. Hardware description languages (HDLs) such as Verilog and VHDL can model the same semantics as software and synthesize the design into a netlist that can be programmed to an FPGA or composed into the logic gates of an ASIC.

Stored-program computers[edit]
The vast majority of software-based computing occurs on machines implementing the von Neumann architecture, collectively known as stored-program computers. Computer programs are stored as data and executed by processors. Such processors must fetch and decode instructions, as well as load data operands from memory (as part of the instruction cycle), to execute the instructions constituting the software program. Relying on a common cache for code and data leads to the "von Neumann bottleneck", a fundamental limitation on the throughput of software on processors implementing the von Neumann architecture. Even in the modified Harvard architecture, where instructions and data have separate caches in the memory hierarchy, there is overhead to decoding instruction opcodes and multiplexing available execution units on a microprocessor or microcontroller, leading to low circuit utilization. Modern processors that provide simultaneous multithreading exploit under-utilization of available processor functional units and instruction level parallelism between different hardware threads.

Hardware execution units[edit]
Hardware execution units do not in general rely on the von Neumann or modified Harvard architectures and do not need to perform the instruction fetch and decode steps of an instruction cycle and incur those stages' overhead. If needed calculations are specified in a register transfer level (RTL) hardware design, the time and circuit area costs that would be incurred by instruction fetch and decoding stages can be reclaimed and put to other uses.
This reclamation saves time, power, and circuit area in computation. The reclaimed resources can be used for increased parallel computation, other functions, communication, or memory, as well as increased input/output capabilities. This comes at the cost of general-purpose utility.

Emerging hardware architectures[edit]
Greater RTL customization of hardware designs allows emerging architectures such as in-memory computing, transport triggered architectures (TTA) and networks-on-chip (NoC) to further benefit from increased locality of data to execution context, thereby reducing computing and communication latency between modules and functional units.
Custom hardware is limited in parallel processing capability only by the area and logic blocks available on the integrated circuit die.[10] Therefore, hardware is much more free to offer massive parallelism than software on general-purpose processors, offering a possibility of implementing the parallel random-access machine (PRAM) model.
It is common to build multicore and manycore processing units out of microprocessor IP core schematics on a single FPGA or ASIC.[11][12][13][14][15] Similarly, specialized functional units can be composed in parallel, as in digital signal processing, without being embedded in a processor IP core. Therefore, hardware acceleration is often employed for repetitive, fixed tasks involving little conditional branching, especially on large amounts of data. This is how Nvidia's CUDA line of GPUs are implemented.

Implementation metrics[edit]
As device mobility has increased, new metrics have been developed that measure the relative performance of specific acceleration protocols, considering characteristics such as physical hardware dimensions, power consumption, and operations throughput. These can be summarized into three categories: task efficiency, implementation efficiency, and flexibility. Appropriate metrics consider the area of the hardware along with both the corresponding operations throughput and energy consumed.[16]

Applications[edit]
Examples of hardware acceleration include bit blit acceleration functionality in graphics processing units (GPUs), use of memristors for accelerating neural networks, and regular expression hardware acceleration for spam control in the server industry, intended to prevent regular expression denial of service (ReDoS) attacks.[17] The hardware that performs the acceleration may be part of a general-purpose CPU, or a separate unit called a hardware accelerator, though they are usually referred to with a more specific term, such as 3D accelerator, or cryptographic accelerator.
Traditionally, processors were sequential (instructions are executed one by one), and were designed to run general purpose algorithms controlled by instruction fetch (for example, moving temporary results to and from a register file). Hardware accelerators improve the execution of a specific algorithm by allowing greater concurrency, having specific datapaths for their temporary variables, and reducing the overhead of instruction control in the fetch-decode-execute cycle.
Modern processors are multi-core and often feature parallel "single-instruction; multiple data" (SIMD) units. Even so, hardware acceleration still yields benefits. Hardware acceleration is suitable for any computation-intensive algorithm which is executed frequently in a task or program. Depending upon the granularity, hardware acceleration can vary from a small functional unit, to a large functional block (like motion estimation in MPEG-2).

Hardware acceleration units by application[edit]




Application

Hardware accelerator

Acronym









Computer graphics
General-purpose computing
GP computing, on Nvidia graphics cards
Ray tracing
Video codec

Graphics processing unit
General-purpose computing on GPU
CUDA architecture
Ray-tracing hardware
Various video acceleration hardware

GPU
GPGPU
CUDA
RTX
N/A









Digital signal processing

Digital signal processor

DSP


Analog signal processing

Field-programmable analog array
Field-programmable RF

FPAA
FPRF


Image processing

Webcam or image processor

IPU


Sound processing

Sound card and sound card mixer

N/A


Computer networking
on a chip
TCP
Input/output

Network processor and network interface controller
Network on a chip
TCP offload engine
IPsec offload[18]
I/O Acceleration Technology

NPU and NIC
NoC
TCPOE or TOE
I/OAT or IOAT


Cryptography
Encryption
ISA
SSL/TLS
Attack
Random number generation

Cryptographic accelerator and secure cryptoprocessor
Hardware-based encryption
AES instruction set
SSL acceleration
Custom hardware attack
Hardware random number generator

N/A


Artificial intelligence
Machine vision/computer vision
Neural networks
Brain simulation

AI accelerator
Vision processing unit
Physical neural network
Neuromorphic engineering

N/A
VPU
PNN
N/A


Multilinear algebra

Tensor processing unit

TPU


Physics simulation

Physics processing unit

PPU


Regular expressions[17]

Regular expression coprocessor

N/A


Data compression[19]

Data compression accelerator

N/A


In-memory processing

Network on a chip and Systolic array

NoC; N/A


Data processing

Data processing unit

DPU


Any computing task

Computer hardware
Field-programmable gate arrays[20]
Application-specific integrated circuits[20]
Complex programmable logic devices
Systems-on-Chip
Multi-processor system-on-chip
Programmable system-on-chip

HW (sometimes)
FPGA
ASIC
CPLD
SoC
MPSoC
PSoC

See also[edit]
Coprocessor
DirectX Video Acceleration (DXVA)
Direct memory access (DMA)
High-level synthesis
C to HDL
Flow to HDL
Soft microprocessor
Flynn's taxonomy of parallel computer architectures
Single instruction, multiple data (SIMD)
Single instruction, multiple threads (SIMT)
Multiple instructions, multiple data (MIMD)
Computer for operations with functions
References[edit]


^ "Microsoft Supercharges Bing Search With Programmable Chips". WIRED. 16 June 2014.

^ "Embedded". Archived from the original on 2007-10-08. Retrieved 2012-08-18. "FPGA Architectures from 'A' to 'Z'" by Clive Maxfield 2006

^ Sinan, Kufeoglu; Mahmut, Ozkuran (2019). "Figure 5. CPU, GPU, FPGA, and ASIC minimum energy consumption between difficulty recalculation.". Energy Consumption of Bitcoin Mining. doi:10.17863/CAM.41230.

^ Kim, Yeongmin; Kong, Joonho; Munir, Arslan (2020). "CPU-Accelerator Co-Scheduling for CNN Acceleration at the Edge". IEEE Access. 8: 211422–211433. Bibcode:2020IEEEA...8u1422K. doi:10.1109/ACCESS.2020.3039278. ISSN 2169-3536.

^ Lin, Yibo; Jiang, Zixuan; Gu, Jiaqi; Li, Wuxi; Dhar, Shounak; Ren, Haoxing; Khailany, Brucek; Pan, David Z. (April 2021). "DREAMPlace: Deep Learning Toolkit-Enabled GPU Acceleration for Modern VLSI Placement". IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems. 40 (4): 748–761. doi:10.1109/TCAD.2020.3003843. ISSN 1937-4151. S2CID 225744481.

^ Lyakhov, Pavel; Valueva, Maria; Valuev, Georgii; Nagornov, Nikolai (2020-12-18). "A Method of Increasing Digital Filter Performance Based on Truncated Multiply-Accumulate Units". Applied Sciences. 10 (24): 9052. doi:10.3390/app10249052. ISSN 2076-3417. Hardware simulation on FPGA increased the digital filter performance.

^ Mohan, Prashanth; Wang, Wen; Jungk, Bernhard; Niederhagen, Ruben; Szefer, Jakub; Mai, Ken (October 2020). "ASIC Accelerator in 28 nm for the Post-Quantum Digital Signature Scheme XMSS". 2020 IEEE 38th International Conference on Computer Design (ICCD). Hartford, CT, USA: IEEE. pp. 656–662. doi:10.1109/ICCD50377.2020.00112. ISBN 978-1-7281-9710-4. S2CID 229330964.

^ Morgan, Timothy Pricket (2014-09-03). "How Microsoft Is Using FPGAs To Speed Up Bing Search". Enterprise Tech. Retrieved 2018-09-18.

^ "Project Catapult". Microsoft Research.

^ MicroBlaze Soft Processor: Frequently Asked Questions Archived 2011-10-27 at the Wayback Machine

^ Vassányi, István (1998). "Implementing processor arrays on FPGAs". Field-Programmable Logic and Applications from FPGAs to Computing Paradigm. Lecture Notes in Computer Science. Vol. 1482. pp. 446–450. doi:10.1007/BFb0055278. ISBN 978-3-540-64948-9.

^ Zhoukun WANG and Omar HAMMAMI. "A 24 Processors System on Chip FPGA Design with Network on Chip". [1]

^ John Kent. "Micro16 Array - A Simple CPU Array"

^ Kit Eaton. "1,000 Core CPU Achieved: Your Future Desktop Will Be a Supercomputer". 2011. [2]

^ "Scientists Squeeze Over 1,000 Cores onto One Chip". 2011. [3] Archived 2012-03-05 at the Wayback Machine

^ Kienle, Frank; Wehn, Norbert; Meyr, Heinrich (December 2011). "On Complexity, Energy- and Implementation-Efficiency of Channel Decoders". IEEE Transactions on Communications. 59 (12): 3301–3310. arXiv:1003.3792. doi:10.1109/tcomm.2011.092011.100157. ISSN 0090-6778. S2CID 13863870.

^ a b "Regular Expressions in hardware". Retrieved 17 July 2014.

^ https://www.intel.com/content/dam/doc/product-brief/intel-pro-100-s-desktop-adapter-datasheet.pdf

^ "Compression Accelerators - Microsoft Research". Microsoft Research. Retrieved 2017-10-07.

^ a b Farabet, Clément, et al. "Hardware accelerated convolutional neural networks for synthetic vision systems[dead link]." Circuits and Systems (ISCAS), Proceedings of 2010 IEEE International Symposium on. IEEE, 2010.


External links[edit]
 Media related to Hardware acceleration at Wikimedia Commons
vteHardware accelerationTheory
Universal Turing machine
Parallel computing
Distributed computing
Applications
GPU
GPGPU
DirectX
Audio
Digital signal processing
Hardware random number generation
Neural processing unit
Cryptography
TLS
Machine vision
Custom hardware attack
scrypt
Networking
Data
Implementations
High-level synthesis
C to HDL
FPGA
ASIC
CPLD
System on a chip
Network on a chip
Architectures
Dataflow
Transport triggered
Multicore
Manycore
Heterogeneous
In-memory computing
Systolic array
Neuromorphic
Related
Programmable logic
Processor
design
chronology
Digital electronics
Virtualization
Hardware emulation
Logic synthesis
Embedded systems

vteGraphics processing unitGPUDesktop
Intel
GT
Xe
Arc
Nvidia
GeForce
Quadro
Tesla
Tegra
AMD
Radeon
Radeon Pro
Instinct
Matrox
InfiniteReality
NEC µPD7220
3dfx Voodoo
S3
Glaze3D
Apple silicon
Jingjia Micro
Mobile
Adreno
Apple silicon
Mali
PowerVR
VideoCore
Vivante
Imageon
Intel 2700G
Architecture
Compute kernel
Fabrication
CMOS
FinFET
MOSFET
Graphics pipeline
Geometry
Vertex
HDR rendering
MAC
Rasterisation
Shading
Ray-tracing
SIMD
SIMT
Tessellation
T&L
Tiled rendering
Unified shader model
Components
Blitter
Geometry processor
Input–output memory management unit
Render output unit
Shader unit
Stream processor
Tensor unit
Texture mapping unit
Video display controller
Video processing unit
Memory
DMA
Framebuffer
SGRAM
GDDR
GDDR2
GDDR3
GDDR4
GDDR5
GDDR6
GDDR7
HBM
HBM2
HBM2E
HBM3
HBM-PIM
HBM3E
Memory bandwidth
Memory controller
Shared graphics memory
Texture memory
VRAM
Form factor
IP core
Discrete graphics
Clustering
Switching
External graphics
Integrated graphics
System on a chip
Performance
Clock rate
Display resolution
Fillrate
Pixel/s
Texel/s
FLOP/s
Frame rate
Performance per watt
Transistor count
Misc
2D
Scrolling
Sprite
Tile
3D
GI
Texture
ASIC
GPGPU
Graphics library
Hardware acceleration
Image processing
Compression
Parallel computing
Vector processor
Video coding
Codec
VLIW

vteDigital electronicsComponents
Transistor
Resistor
Inductor
Capacitor
Printed electronics
Printed circuit board
Electronic circuit
Flip-flop
Memory cell
Combinational logic
Sequential logic
Logic gate
Boolean circuit
Integrated circuit (IC)
Hybrid integrated circuit (HIC)
Mixed-signal integrated circuit
Three-dimensional integrated circuit (3D IC)
Emitter-coupled logic (ECL)
Erasable programmable logic device (EPLD)
Macrocell array
Programmable logic array (PLA)
Programmable logic device (PLD)
Programmable Array Logic (PAL)
Generic Array Logic (GAL)
Complex programmable logic device (CPLD)
Field-programmable gate array (FPGA)
Field-programmable object array (FPOA)
Application-specific integrated circuit (ASIC)
Tensor Processing Unit (TPU)
Theory
Digital signal
Boolean algebra
Logic synthesis
Logic in computer science
Computer architecture
Digital signal
Digital signal processing
Circuit minimization
Switching circuit theory
Gate equivalent
Design
Logic synthesis
Place and route
Placement
Routing
Transaction-level modeling
Register-transfer level
Hardware description language
High-level synthesis
Formal equivalence checking
Synchronous logic
Asynchronous logic
Finite-state machine
Hierarchical state machine
Applications
Computer hardware
Hardware acceleration
Digital audio
radio
Digital photography
Digital telephone
Digital video
cinematography
television
Electronic literature
Design issues
Metastability
Runt pulse





Retrieved from "https://en.wikipedia.org/w/index.php?title=Hardware_acceleration&oldid=1284863668"
Categories: Hardware accelerationApplication-specific integrated circuitsCentral processing unitComputer optimizationGate arraysGraphics hardwareHidden categories: Webarchive template wayback linksAll articles with dead external linksArticles with dead external links from July 2022Articles with short descriptionShort description is different from WikidataArticles needing additional references from September 2014All articles needing additional referencesCommons category link from WikidataArticles with example C code






 This page was last edited on 10 April 2025, at 05:25 (UTC).
Text is available under the Creative Commons Attribution-ShareAlike 4.0 License;
additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.


Privacy policy
About Wikipedia
Disclaimers
Contact Wikipedia
Code of Conduct
Developers
Statistics
Cookie statement
Mobile view














Search













Search









Toggle the table of contents







Hardware acceleration




























23 languages


Add topic
















